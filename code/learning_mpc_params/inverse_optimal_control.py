# í•µì‹¬ IOC ì•Œê³ ë¦¬ì¦˜

"""
Inverse Optimal Control using Relaxed KKT Conditions

ì „ë¬¸ê°€ ì‹œì—° ë°ì´í„°ë¡œë¶€í„° MPC ë¹„ìš©í•¨ìˆ˜ íŒŒë¼ë¯¸í„°ë¥¼ ì—­ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.
KKT ì¡°ê±´ ì™„í™”(Relaxed KKT) ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

í•µì‹¬ ì•„ì´ë””ì–´:
    ìµœì ì„± ì¡°ê±´ âˆ‡L = 0ì„ ì •í™•íˆ ë§Œì¡±ì‹œí‚¤ëŠ” ëŒ€ì‹ ,
    â€–âˆ‡Lâ€–Â²ì„ ìµœì†Œí™”í•˜ëŠ” íŒŒë¼ë¯¸í„° Î¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
"""

import numpy as np
import os
import mujoco
from scipy.optimize import minimize, LinearConstraint
import matplotlib.pyplot as plt
from typing import Dict, Tuple, List
from tqdm import tqdm


class InverseOptimalControl:
    """
    KKT ì¡°ê±´ ì™„í™”ë¥¼ ì´ìš©í•œ ì—­ìµœì ì œì–´
    
    ì „ë¬¸ê°€ ì‹œì—°ìœ¼ë¡œë¶€í„° MPC ë¹„ìš©í•¨ìˆ˜ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, model, joint_ids, horizon, dt):
        """
        Args:
            model: MuJoCo model
            joint_ids: ì œì–´í•  ê´€ì ˆ ì¸ë±ìŠ¤
            horizon: MPC ì˜ˆì¸¡ êµ¬ê°„
            dt: ì‹œê°„ ê°„ê²©
        """
        self.model = model
        self.joint_ids = joint_ids
        self.nq = len(joint_ids)
        self.horizon = horizon
        self.dt = dt
        
        # MPC ë™ì—­í•™ ê³„ì‚°ìš© ë°ì´í„°
        self.data_temp = mujoco.MjData(model)
        
        # íŒŒë¼ë¯¸í„° ì´ˆê¸°ê°’ ì €ì¥
        self.theta_init = None
        
    def load_demonstration_data(self, data_path):
        """
        ì‹œì—° ë°ì´í„° ë¡œë“œ
        
        Args:
            data_path: .npz íŒŒì¼ ê²½ë¡œ
            
        Returns:
            demonstrations: List of dicts with keys:
                - 't': time
                - 'q': joint positions
                - 'qdot': joint velocities  
                - 'u': control inputs (tau)
                - 'q_ref': reference positions
        """
        data = np.load(data_path)
        
        # ì‹œì—° ë°ì´í„°ë¥¼ ì‹œê°„ êµ¬ê°„ìœ¼ë¡œ ë¶„í• 
        demonstrations = []
        
        # ì „ì²´ ë°ì´í„°ë¥¼ horizon ê¸¸ì´ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆ”
        n_samples = len(data['q'])
        segment_length = self.horizon + 1
        
        for start_idx in range(0, n_samples - segment_length, segment_length // 2):
            end_idx = start_idx + segment_length
            
            demo = {
                'q': data['q'][start_idx:end_idx],
                'qdot': data['qdot'][start_idx:end_idx],
                'u': data['tau_mpc'][start_idx:end_idx],
                't': np.arange(segment_length) * self.dt
            }
            
            demonstrations.append(demo)
        
        print(f"âœ… Loaded {len(demonstrations)} demonstration segments")
        return demonstrations
    
    def compute_gradient_norm(self, theta, demonstration):
        """
        ì£¼ì–´ì§„ íŒŒë¼ë¯¸í„° Î¸ì— ëŒ€í•´ â€–âˆ‡Lâ€–Â² ê³„ì‚°
        
        ì´ê²ƒì´ ëª©ì í•¨ìˆ˜ì…ë‹ˆë‹¤. ì´ ê°’ì„ ìµœì†Œí™”í•˜ëŠ” Î¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

        ì£¼ì–´ì§„ ë¹„ìš© ê°€ì¤‘ì¹˜ Î¸ê°€ ìˆì„ ë•Œ, ì „ë¬¸ê°€ ì‹œì—°ì´ ê·¸ ë¹„ìš©ì— ëŒ€í•´ â€˜ê±°ì˜ ìµœì â€™ì´ì—ˆëŠ”ì§€ë¥¼ KKT ì¡°ê±´ì˜ ì”ì°¨(âˆ‡L) í¬ê¸°ë¡œ í‰ê°€í•œë‹¤.
        
        Args:
            theta: ë¹„ìš©í•¨ìˆ˜ íŒŒë¼ë¯¸í„° [q_pos, q_vel, r_tau, q_terminal] (4ê°œ)
            demonstration: ì‹œì—° ë°ì´í„° dict
            
        Returns:
            gradient_norm_squared: â€–âˆ‡Lâ€–Â² ê°’
        """

        # íŒŒë¼ë¯¸í„° ì–¸íŒ©
        q_pos_w, q_vel_w, r_tau_w, q_term_w, q_vel_term_w, q_vel_ref_w = theta
        
        q_demo = demonstration['q']       # (horizon+1, nq)
        qdot_demo = demonstration['qdot'] # (horizon+1, nq)
        u_demo = demonstration['u']       # (horizon, nq)
        
        # ì „ë¬¸ê°€ì˜ ëª©í‘œ ìƒíƒœ (ì‹œì—°ì˜ ë§ˆì§€ë§‰ì„ ëª©í‘œë¡œ ê°€ì •í•˜ê±°ë‚˜ ë³„ë„ì˜ ref ì‚¬ìš©)
        q_ref = q_demo[-1]
        qdot_ref = qdot_demo[-1] 
        
        grad_L = np.zeros((self.horizon, self.nq))
        
        for k in range(self.horizon):
            # 1. âˆ‚l_k/âˆ‚u_k (í˜„ì¬ ìŠ¤í…ì˜ Control Effort ë¯¸ë¶„)
            dldu_direct = 2 * r_tau_w * u_demo[k]
            
            # 2. âˆ‚x_{k+1}/âˆ‚u_k (System Dynamics ë¯¸ë¶„ - ìˆ˜ì¹˜ ë¯¸ë¶„)
            dynamics_grad_q = np.zeros((self.nq, self.nq))    # âˆ‚q_{k+1}/âˆ‚u_k
            dynamics_grad_qdot = np.zeros((self.nq, self.nq)) # âˆ‚qdot_{k+1}/âˆ‚u_k
            
            epsilon = 1e-4
            for i in range(self.nq):
                u_plus = u_demo[k].copy();  u_plus[i] += epsilon
                q_next_plus, qdot_next_plus = self._forward_dynamics(q_demo[k], qdot_demo[k], u_plus) # ë‚´ë¶€ì—ì„œ mj_forward í˜¸ì¶œ
                
                u_minus = u_demo[k].copy(); u_minus[i] -= epsilon
                q_next_minus, qdot_next_minus = self._forward_dynamics(q_demo[k], qdot_demo[k], u_minus)
                
                q_p, qd_p = self._forward_dynamics(q_demo[k], qdot_demo[k], u_plus)
                q_m, qd_m = self._forward_dynamics(q_demo[k], qdot_demo[k], u_minus)
                
                dynamics_grad_q[:, i] = (q_p - q_m) / (2 * epsilon)
                dynamics_grad_qdot[:, i] = (qd_p - qd_m) / (2 * epsilon)

            # 3. âˆ‚J/âˆ‚u_k ê³„ì‚° (Chain Rule)
            # u_këŠ” k+1 ë²ˆì§¸ì˜ ìƒíƒœ ì˜¤ì°¨ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
            
            if k < self.horizon - 1:
                # --- Running Cost ì˜ì—­ ---
                # q_error = q_{k+1} - q_ref
                de_dq = 2 * q_pos_w * (q_demo[k+1] - q_ref)
                # qdot_error = qdot_{k+1} - qdot_ref
                de_dqdot = 2 * q_vel_ref_w * (qdot_demo[k+1] - qdot_ref)
                # Damping (ì†ë„ ì ˆëŒ€ê°’ í˜ë„í‹°)
                de_dqdot_damping = 2 * q_vel_w * qdot_demo[k+1]
                
                dldu_chain = dynamics_grad_q.T @ de_dq + dynamics_grad_qdot.T @ (de_dqdot + de_dqdot_damping)
            
            else:
                # --- Terminal Cost ì˜ì—­ (ë§ˆì§€ë§‰ ì…ë ¥ u_{N-1}ì´ ìµœì¢… ìƒíƒœì— ë¯¸ì¹˜ëŠ” ì˜í–¥) ---
                de_dq_term = 2 * q_term_w * (q_demo[k+1] - q_ref)
                de_dqdot_term = 2 * q_vel_term_w * (qdot_demo[k+1] - qdot_ref)
                
                dldu_chain = dynamics_grad_q.T @ de_dq_term + dynamics_grad_qdot.T @ de_dqdot_term
            
            grad_L[k] = dldu_direct + dldu_chain
        
        return np.sum(grad_L ** 2)


    
    def _forward_dynamics(self, q, qdot, u):
        """
        í•œ ìŠ¤í… ë™ì—­í•™ ì‹œë®¬ë ˆì´ì…˜ (RK4)
        
        Args:
            q: ê´€ì ˆ ìœ„ì¹˜
            qdot: ê´€ì ˆ ì†ë„
            u: ì œì–´ ì…ë ¥
            
        Returns:
            q_next: ë‹¤ìŒ ìœ„ì¹˜
            qdot_next: ë‹¤ìŒ ì†ë„
        """
        # MuJoCo ìƒíƒœ ì„¤ì •
        self.data_temp.qpos[self.joint_ids] = q
        self.data_temp.qvel[self.joint_ids] = qdot
        
        # Forward dynamics
        mujoco.mj_forward(self.model, self.data_temp)
        
        # Mass matrix
        M_full = np.zeros((self.model.nv, self.model.nv))
        mujoco.mj_fullM(self.model, M_full, self.data_temp.qM)
        M = M_full[np.ix_(self.joint_ids, self.joint_ids)]
        
        # Bias force
        bias = self.data_temp.qfrc_bias[self.joint_ids]
        
        # ê°€ì†ë„ ê³„ì‚°
        qddot = np.linalg.solve(M, u - bias)
        
        # RK4 ì ë¶„
        k1_v = qdot
        k1_a = qddot
        
        k2_v = qdot + 0.5 * self.dt * k1_a
        k2_a = qddot  # ê°„ë‹¨í™”: ê°™ì€ ê°€ì†ë„ ì‚¬ìš©
        
        k3_v = qdot + 0.5 * self.dt * k2_a
        k3_a = qddot
        
        k4_v = qdot + self.dt * k3_a
        k4_a = qddot
        
        q_next = q + (self.dt / 6.0) * (k1_v + 2*k2_v + 2*k3_v + k4_v)
        qdot_next = qdot + (self.dt / 6.0) * (k1_a + 2*k2_a + 2*k3_a + 4*k4_a)
        
        return q_next, qdot_next
    
    def learn_cost_weights(self, demonstrations, theta_init):
        """
        ì‹œì—° ë°ì´í„°ë¡œë¶€í„° ë¹„ìš©í•¨ìˆ˜ ê°€ì¤‘ì¹˜ í•™ìŠµ
        
        Args:
            demonstrations: ì‹œì—° ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            theta_init: ì´ˆê¸° íŒŒë¼ë¯¸í„° (Noneì´ë©´ ìë™ ì„¤ì •)
            
        Returns:
            theta_opt: ìµœì  íŒŒë¼ë¯¸í„°
            result: ìµœì í™” ê²°ê³¼
        """
        # ì´ˆê¸° íŒŒë¼ë¯¸í„° ì„¤ì •
        if theta_init is None:
            # í•©ë¦¬ì ì¸ ì´ˆê¸°ê°’
            theta_init = np.array([
                1000.0,  # q_pos_weight
                50.0,    # q_vel_weight  
                0.01,    # r_tau_weight
                1500.0,  # q_terminal_weight
                50.0,    # q_vel_terminal_weight
                10.0     # q_vel_ref_weight
            ])
        
        self.theta_init = theta_init.copy()
        log_theta_init = np.log(theta_init)
        
        print("\n" + "="*60)
        print("ğŸ¯ Inverse Optimal Control: Learning MPC Cost Weights")
        print("="*60)
        print(f"Method: Relaxed KKT (minimize â€–âˆ‡Lâ€–Â²)")
        print(f"Demonstrations: {len(demonstrations)} segments")
        print(f"Horizon: {self.horizon}")
        print(f"Initial parameters: {theta_init}")
        
        # ëª©ì í•¨ìˆ˜: ëª¨ë“  ì‹œì—°ì— ëŒ€í•œ í‰ê·  â€–âˆ‡Lâ€–Â²
        def objective(log_theta):
            # 2. ìˆ˜ì¹˜ì  ë°œì‚° ë°©ì§€: ê°’ì´ ë„ˆë¬´ ì»¤ì§€ê±°ë‚˜ ì‘ì•„ì§€ì§€ ì•Šê²Œ í´ë¦¬í•‘
            log_theta = np.clip(log_theta, -20, 20)
            theta = np.exp(log_theta)
            total_grad_norm = 0.0

            # ì§„í–‰ë°” ì¶œë ¥ (descë¥¼ í†µí•´ í˜„ì¬ Loss ìƒíƒœ í‘œì‹œ)
            pbar = tqdm(demonstrations, desc="Computing IOC Gradient", leave=False)
            for demo in pbar: 
                grad_norm_sq = self.compute_gradient_norm(theta, demo)
                total_grad_norm += grad_norm_sq
            
            avg_grad_norm = total_grad_norm / len(demonstrations)
            return avg_grad_norm
        
        # ì œì•½ì¡°ê±´: ëª¨ë“  ê°€ì¤‘ì¹˜ëŠ” ì–‘ìˆ˜
        bounds = [(1e-3, None)] * len(theta_init)
        
        # ì •ê·œí™” ì œì•½: í•©ì´ ì¼ì • (ìŠ¤ì¼€ì¼ ê³ ì •)
        # ì´ê²ƒì´ ì—†ìœ¼ë©´ ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ 0ìœ¼ë¡œ ìˆ˜ë ´í•  ìˆ˜ ìˆìŒ
        total_weight = np.sum(theta_init)
        constraints = {
            'type': 'eq',
            'fun': lambda theta: np.sum(theta) - total_weight
        }
        
        print("\nâ–¶ï¸  Starting optimization...")
        print(f"   Bounds: all weights > 0")
        print(f"   Constraint: Î£Î¸ = {total_weight:.1f}")
        
        # ìµœì í™” ì‹¤í–‰
        result = minimize(
            objective,
            log_theta_init,
            method='L-BFGS-B',
            # bounds=bounds,
            # constraints=constraints,
            options={
                'maxiter': 100,
                'ftol': 1e-4,
                'disp': True,
                'eps' : 1e-3
            }
        )
        
        # theta_opt = result.x
        theta_opt = np.exp(np.clip(result.x, -20, 20))
        
        print("\nâœ… Optimization completed!")
        print(f"   Success: {result.success}")
        print(f"   Final â€–âˆ‡Lâ€–Â²: {result.fun:.6e}")
        print(f"   Iterations: {result.nit}")
        
        return theta_opt, result
    
    def compare_parameters(self, theta_learned, theta_original=None):
        """
        í•™ìŠµëœ íŒŒë¼ë¯¸í„°ì™€ ì›ë˜ íŒŒë¼ë¯¸í„° ë¹„êµ
        
        Args:
            theta_learned: í•™ìŠµëœ íŒŒë¼ë¯¸í„°
            theta_original: ì›ë˜ íŒŒë¼ë¯¸í„° (Noneì´ë©´ ì´ˆê¸°ê°’ ì‚¬ìš©)
        """
        if theta_original is None:
            theta_original = self.theta_init
        
        param_names = ['Q_pos', 'Q_vel', 'R_tau', 'Q_terminal']
        
        print("\n" + "="*60)
        print("ğŸ“Š Parameter Comparison")
        print("="*60)
        print(f"{'Parameter':<15} {'Original':>12} {'Learned':>12} {'Ratio':>10}")
        print("-"*60)
        
        for i, name in enumerate(param_names):
            orig = theta_original[i]
            learned = theta_learned[i]
            ratio = learned / orig if orig != 0 else float('inf')
            
            print(f"{name:<15} {orig:>12.2f} {learned:>12.2f} {ratio:>10.2f}x")
        
        print("="*60)
    
    def visualize_results(self, theta_learned, demonstrations, n_samples=3):
        """
        í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
        
        Args:
            theta_learned: í•™ìŠµëœ íŒŒë¼ë¯¸í„°
            demonstrations: ì‹œì—° ë°ì´í„°
            n_samples: ì‹œê°í™”í•  ì‹œì—° ê°œìˆ˜
        """
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # ìƒ˜í”Œ ì„ íƒ
        demo_indices = np.linspace(0, len(demonstrations)-1, n_samples, dtype=int)
        
        for demo_idx in demo_indices:
            demo = demonstrations[demo_idx]
            
            # ê¸°ìš¸ê¸° ê³„ì‚°
            grad_norm_init = self.compute_gradient_norm(self.theta_init, demo)
            grad_norm_learned = self.compute_gradient_norm(theta_learned, demo)
            
            # ì‹œì—° ë°ì´í„°
            t = demo['t']
            q = demo['q'][:, 0]  # ì²« ë²ˆì§¸ ê´€ì ˆë§Œ
            qdot = demo['qdot'][:, 0]
            u = demo['u'][:, 0]
            
            # Plot 1: Position trajectory
            axes[0, 0].plot(t, q, alpha=0.6, label=f'Demo {demo_idx}')
            
            # Plot 2: Velocity  
            axes[0, 1].plot(t, qdot, alpha=0.6)
            
            # Plot 3: Control input
            axes[1, 0].plot(t, u, alpha=0.6)
        
        # Plot 4: Gradient norm comparison
        grad_norms_init = []
        grad_norms_learned = []
        
        for demo in demonstrations:
            grad_norms_init.append(
                np.sqrt(self.compute_gradient_norm(self.theta_init, demo))
            )
            grad_norms_learned.append(
                np.sqrt(self.compute_gradient_norm(theta_learned, demo))
            )
        
        x = np.arange(len(demonstrations))
        axes[1, 1].bar(x - 0.2, grad_norms_init, 0.4, 
                      label='Initial Î¸', alpha=0.7)
        axes[1, 1].bar(x + 0.2, grad_norms_learned, 0.4,
                      label='Learned Î¸', alpha=0.7)
        
        # ë ˆì´ë¸” ì„¤ì •
        axes[0, 0].set_ylabel('Position [rad]')
        axes[0, 0].set_title('Demonstration Trajectories - Position')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        axes[0, 1].set_ylabel('Velocity [rad/s]')
        axes[0, 1].set_title('Demonstration Trajectories - Velocity')
        axes[0, 1].grid(True, alpha=0.3)
        
        axes[1, 0].set_xlabel('Time [s]')
        axes[1, 0].set_ylabel('Torque [Nm]')
        axes[1, 0].set_title('Demonstration Trajectories - Control')
        axes[1, 0].grid(True, alpha=0.3)
        
        axes[1, 1].set_xlabel('Demonstration Index')
        axes[1, 1].set_ylabel('â€–âˆ‡Lâ€–')
        axes[1, 1].set_title('KKT Gradient Norm Comparison')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        base_dir = os.path.dirname(os.path.abspath(__file__))
        save_path = os.path.join(base_dir, "ioc_results.png")
        plt.savefig(save_path, dpi=150)
        # plt.savefig('/mnt/user-data/outputs/ioc_results.png', dpi=150)
        print("\nâœ… Visualization saved: ioc_results.png")
        plt.show()


def apply_learned_weights_to_mpc(mpc_controller, theta_learned):
    """
    í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ MPC ì»¨íŠ¸ë¡¤ëŸ¬ì— ì ìš©
    
    Args:
        mpc_controller: TorqueMPC ì¸ìŠ¤í„´ìŠ¤
        theta_learned: í•™ìŠµëœ íŒŒë¼ë¯¸í„° [q_pos, q_vel, r_tau, q_terminal]
    """
    nq = mpc_controller.nq
    
    Q_pos = np.eye(nq) * theta_learned[0]
    Q_vel = np.eye(nq) * theta_learned[1]
    R_tau = np.eye(nq) * theta_learned[2]
    Q_terminal = np.eye(nq) * theta_learned[3]
    Q_vel_terminal = np.eye(nq) * theta_learned[4]
    Q_vel_ref = np.eye(nq) * theta_learned[5]
    
    mpc_controller.update_cost_weights(
        Q_pos=Q_pos,
        Q_vel=Q_vel,
        R_tau=R_tau,
        Q_terminal=Q_terminal,
        Q_vel_terminal=Q_vel_terminal,
        Q_vel_ref=Q_vel_ref
    )
    
    print("\nâœ… Learned weights applied to MPC controller!")
    print(f"   Q_pos: {theta_learned[0]:.2f}")
    print(f"   Q_vel: {theta_learned[1]:.2f}")
    print(f"   R_tau: {theta_learned[2]:.2f}")
    print(f"   Q_terminal: {theta_learned[3]:.2f}")
    print(f"   Q_vel_terminal: {theta_learned[4]:.2f}")
    print(f"   Q_vel_ref: {theta_learned[5]:.2f}")