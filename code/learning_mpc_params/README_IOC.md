# Inverse Optimal Control for MPC Parameter Learning

## ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **KKT ì¡°ê±´ ì™„í™”(Relaxed KKT Conditions)**ë¥¼ ì´ìš©í•œ ì—­ìµœì ì œì–´(Inverse Optimal Control)ë¡œ MPC ë¹„ìš©í•¨ìˆ˜ íŒŒë¼ë¯¸í„°ë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

### í•µì‹¬ ì•„ì´ë””ì–´

```
ì „ë¬¸ê°€ ì‹œì—° ë°ì´í„°
    â†“
ì—­ìµœì ì œì–´ (KKT ì™„í™”)
    â†“
MPC ë¹„ìš©í•¨ìˆ˜ ê°€ì¤‘ì¹˜
    â†“
ê°œì„ ëœ ì œì–´ ì„±ëŠ¥
```

## ì„¤ì¹˜ ë° ìš”êµ¬ì‚¬í•­

```bash
# Python íŒ¨í‚¤ì§€
pip install numpy scipy matplotlib torch mujoco

# MuJoCo ëª¨ë¸ í•„ìš”
```

## ì‚¬ìš© ë°©ë²•

### Step 1: ì‹œì—° ë°ì´í„° ìƒì„±

ì›ë˜ MPC íŒŒë¼ë¯¸í„°ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì—¬ "ì „ë¬¸ê°€ ì‹œì—°" ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

```bash
python main.py
```

**ì¶œë ¥:**
- `delta_tau_dataset.npz`: ì‹œì—° ë°ì´í„° (ìƒíƒœ, ì œì–´ ì…ë ¥)
- `result_mpc_only.npz`: ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ë¹„êµìš©)

### Step 2: MPC íŒŒë¼ë¯¸í„° í•™ìŠµ

ì‹œì—° ë°ì´í„°ë¡œë¶€í„° KKT ì¡°ê±´ ì™„í™”ë¥¼ ì´ìš©í•˜ì—¬ ìµœì  ë¹„ìš©í•¨ìˆ˜ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

```bash
python learn_mpc_weights.py
```

**ìˆ˜í–‰ ê³¼ì •:**
1. ì‹œì—° ë°ì´í„° ë¡œë“œ ë° ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• 
2. ëª©ì í•¨ìˆ˜ ì •ì˜: `min Î£â€–âˆ‡L(Î¸)â€–Â²`
3. SLSQP ìµœì í™”ë¡œ Î¸ íƒìƒ‰
4. í•™ìŠµëœ íŒŒë¼ë¯¸í„° ì €ì¥

**ì¶œë ¥:**
- `learned_mpc_weights.npz`: í•™ìŠµëœ ê°€ì¤‘ì¹˜
- `learned_weights_config.py`: Python config íŒŒì¼
- `ioc_results.png`: ì‹œê°í™” ê²°ê³¼

### Step 3: í•™ìŠµëœ íŒŒë¼ë¯¸í„°ë¡œ MPC ì‹¤í–‰

í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.

```bash
python apply_learned_mpc.py
```

**ì¶œë ¥:**
- `result_mpc_learned.npz`: í•™ìŠµëœ ê°€ì¤‘ì¹˜ì˜ ì„±ëŠ¥
- ì›ë˜ ê°€ì¤‘ì¹˜ vs í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¹„êµí‘œ

## íŒŒì¼ êµ¬ì¡°

```
.
â”œâ”€â”€ inverse_optimal_control.py   # í•µì‹¬ IOC ì•Œê³ ë¦¬ì¦˜
â”œâ”€â”€ learn_mpc_weights.py         # í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ apply_learned_mpc.py         # í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì ìš©
â”œâ”€â”€ README_IOC.md                # ì´ ë¬¸ì„œ
â”‚
â”œâ”€â”€ dataGet/
â”‚   â”œâ”€â”€ main.py                  # ì›ë˜ MPC ì‹¤í–‰
â”‚   â”œâ”€â”€ mpc_controller.py        # MPC ì»¨íŠ¸ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ config.py                # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ learned_mpc_weights.npz
    â”œâ”€â”€ ioc_results.png
    â””â”€â”€ ...
```

## ì£¼ìš” í´ë˜ìŠ¤ ë° í•¨ìˆ˜

### `InverseOptimalControl`

ì—­ìµœì ì œì–´ì˜ í•µì‹¬ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
from inverse_optimal_control import InverseOptimalControl

# IOC ê°ì²´ ìƒì„±
ioc = InverseOptimalControl(
    model=mujoco_model,
    joint_ids=[0, 1, 2],
    horizon=20,
    dt=0.005
)

# ì‹œì—° ë°ì´í„° ë¡œë“œ
demos = ioc.load_demonstration_data("delta_tau_dataset.npz")

# ê°€ì¤‘ì¹˜ í•™ìŠµ
theta_learned, result = ioc.learn_cost_weights(demos)
```

**ì£¼ìš” ë©”ì„œë“œ:**

- `load_demonstration_data(path)`: ì‹œì—° ë°ì´í„° ë¡œë“œ
- `compute_gradient_norm(theta, demo)`: â€–âˆ‡Lâ€–Â² ê³„ì‚°
- `learn_cost_weights(demos, theta_init)`: ìµœì í™” ì‹¤í–‰
- `compare_parameters(theta_learned, theta_original)`: íŒŒë¼ë¯¸í„° ë¹„êµ
- `visualize_results(theta_learned, demos)`: ê²°ê³¼ ì‹œê°í™”

### `apply_learned_weights_to_mpc()`

í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ MPC ì»¨íŠ¸ë¡¤ëŸ¬ì— ì ìš©í•©ë‹ˆë‹¤.

```python
from inverse_optimal_control import apply_learned_weights_to_mpc

apply_learned_weights_to_mpc(mpc_controller, theta_learned)
```

## ìˆ˜í•™ì  ë°°ê²½

### ë¬¸ì œ ì •ì‹í™”

ì „ë¬¸ê°€ ì‹œì—° `U_t = [u(0), ..., u(N)]`ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì–´ë–¤ ë¹„ìš©í•¨ìˆ˜ë¥¼ ìµœì í™”í–ˆëŠ”ì§€ ì—­ìœ¼ë¡œ ì¶”ì •í•©ë‹ˆë‹¤.

**ë¹„ìš©í•¨ìˆ˜ íŒŒë¼ë¯¸í„°í™”:**
```
l(x, u, Î¸) = Î¸â‚Â·â€–q - q_refâ€–Â² + Î¸â‚‚Â·â€–qdotâ€–Â² + Î¸â‚ƒÂ·â€–uâ€–Â²
```

**ëª©í‘œ:** Î¸ = [Î¸â‚, Î¸â‚‚, Î¸â‚ƒ, Î¸â‚„] ì°¾ê¸°

### KKT ì¡°ê±´

ìµœì  ì œì–´ `U*`ëŠ” ë‹¤ìŒ KKT ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:

```
âˆ‡_U L(U, Î¸)|_{U=U_t} = 0    (Stationarity)
Î»áµ€g(U_t) = 0                 (Complementarity)
Î» â‰¥ 0                        (Dual Feasibility)
```

ì—¬ê¸°ì„œ `L = ë¹„ìš©í•¨ìˆ˜ + Î»áµ€Â·ì œì•½ì¡°ê±´`

### KKT ì¡°ê±´ ì™„í™”

ì •í™•í•œ ì¡°ê±´ ë§Œì¡±ì´ ì–´ë ¤ìš°ë¯€ë¡œ ë‹¤ìŒ ë¬¸ì œë¥¼ í’‰ë‹ˆë‹¤:

```
minimize_{Î¸}  â€–âˆ‡_U L(U, Î¸)|_{U=U_t}â€–Â²

subject to:   Î¸ â‰¥ 0
              Î£Î¸áµ¢ = const  (ì •ê·œí™”)
```

**ì§ê´€:**
- ê¸°ìš¸ê¸°ë¥¼ ì •í™•íˆ 0ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ì—†ë‹¤ë©´
- ê¸°ìš¸ê¸°ë¥¼ ìµœëŒ€í•œ 0ì— ê°€ê¹ê²Œ!

## ê²°ê³¼ í•´ì„

### í•™ìŠµ ì„±ê³µ ì§€í‘œ

1. **Optimization Success**: `True`ì—¬ì•¼ í•¨
2. **Final â€–âˆ‡Lâ€–Â²**: ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ (< 1e-6 ê¶Œì¥)
3. **Parameter Changes**: í•©ë¦¬ì ì¸ ë²”ìœ„ (0.1x ~ 10x)

### ì„±ëŠ¥ ë¹„êµ

`apply_learned_mpc.py` ì‹¤í–‰ ê²°ê³¼ì—ì„œ í™•ì¸:

```
ğŸ“Š Performance Comparison: Original vs Learned

Metric                   Original      Learned    Winner
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RMSE (ì „ì²´)               0.0234        0.0189   âœ… Learned
Rise Time                 2.456         2.123   âœ… Learned
Overshoot                12.3 %         8.7 %   âœ… Learned
...
```

### ì‹œê°í™” ë¶„ì„

`ioc_results.png`ì—ì„œ í™•ì¸:

1. **Position Trajectory**: ì‹œì—° ê¶¤ì  ìƒ˜í”Œ
2. **Velocity Trajectory**: ì†ë„ í”„ë¡œíŒŒì¼
3. **Control Input**: í† í¬ ì…ë ¥
4. **â€–âˆ‡Lâ€– Comparison**: ì´ˆê¸° vs í•™ìŠµëœ íŒŒë¼ë¯¸í„°ì˜ ê¸°ìš¸ê¸° norm

## ê³ ê¸‰ ì„¤ì •

### ìµœì í™” ì˜µì…˜ ìˆ˜ì •

`inverse_optimal_control.py`ì—ì„œ:

```python
result = minimize(
    objective,
    theta_init,
    method='SLSQP',
    bounds=bounds,
    constraints=constraints,
    options={
        'maxiter': 100,      # ë°˜ë³µ íšŸìˆ˜
        'ftol': 1e-6,        # í•¨ìˆ˜ê°’ í—ˆìš© ì˜¤ì°¨
        'disp': True         # ì§„í–‰ìƒí™© ì¶œë ¥
    }
)
```

### ë‹¤ë¥¸ ìµœì í™” ë°©ë²• ì‹œë„

```python
# Trust-Region ë°©ë²•
from scipy.optimize import minimize

result = minimize(
    objective,
    theta_init,
    method='trust-constr',
    ...
)

# Global optimization (ëŠë¦¬ì§€ë§Œ ë” ê°•ê±´)
from scipy.optimize import differential_evolution

bounds_list = [(1e-3, 1e5)] * 4
result = differential_evolution(
    objective,
    bounds_list,
    ...
)
```

### íŒŒë¼ë¯¸í„° ë²”ìœ„ ì¡°ì •

í•©ë¦¬ì ì¸ íƒìƒ‰ ë²”ìœ„ ì„¤ì •:

```python
bounds = [
    (100, 5000),    # Q_pos
    (10, 200),      # Q_vel
    (1e-4, 1.0),    # R_tau
    (500, 10000)    # Q_terminal
]
```

## ë¬¸ì œ í•´ê²°

### Q1: "Optimization failed" ì˜¤ë¥˜

**ì›ì¸:** ì´ˆê¸°ê°’ì´ ë‚˜ì˜ê±°ë‚˜ ì œì•½ì¡°ê±´ì´ ë„ˆë¬´ ì—„ê²©í•¨

**í•´ê²°:**
1. `theta_init` ê°’ ì¡°ì •
2. `ftol` ê°’ ì™„í™” (1e-6 â†’ 1e-4)
3. `maxiter` ì¦ê°€ (100 â†’ 200)

### Q2: í•™ìŠµëœ íŒŒë¼ë¯¸í„°ê°€ ì´ìƒí•¨ (ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìŒ)

**ì›ì¸:** ì •ê·œí™” ì œì•½ ë¶€ì¡±

**í•´ê²°:**
```python
# ì •ê·œí™” ê°•ë„ ì¡°ì •
constraints = [
    {'type': 'eq', 'fun': lambda Î¸: np.sum(Î¸) - 2550.0},
    {'type': 'ineq', 'fun': lambda Î¸: Î¸[0] - 100},  # Q_pos í•˜í•œ
    {'type': 'ineq', 'fun': lambda Î¸: 5000 - Î¸[0]}  # Q_pos ìƒí•œ
]
```

### Q3: â€–âˆ‡Lâ€–Â²ì´ ì¤„ì–´ë“¤ì§€ ì•ŠìŒ

**ì›ì¸:** 
1. ì‹œì—° ë°ì´í„°ê°€ ì‹¤ì œë¡œ ìµœì ì´ ì•„ë‹˜
2. ë¹„ìš©í•¨ìˆ˜ í˜•íƒœê°€ ì ì ˆí•˜ì§€ ì•ŠìŒ

**í•´ê²°:**
1. ë” ì¢‹ì€ ì‹œì—° ìˆ˜ì§‘
2. ë¹„ìš©í•¨ìˆ˜ íŒŒë¼ë¯¸í„°í™” ë³€ê²½

### Q4: í•™ìŠµëœ ê°€ì¤‘ì¹˜ì˜ ì„±ëŠ¥ì´ ë” ë‚˜ì¨

**ì›ì¸:**
1. Overfitting (ì‹œì—°ì—ë§Œ ìµœì í™”)
2. ì‹œì—° í’ˆì§ˆì´ ë‚®ìŒ

**í•´ê²°:**
1. ë” ë‹¤ì–‘í•œ ì‹œì—° ìˆ˜ì§‘
2. L2 ì •ê·œí™” ì¶”ê°€:
```python
def objective(theta):
    grad_norm = ...
    regularization = 0.01 * np.sum((theta - theta_init)**2)
    return grad_norm + regularization
```

## í™•ì¥ ê°€ëŠ¥ì„±

### 1. ë‹¤ì¤‘ ëª©í‘œ ìµœì í™”

ì—¬ëŸ¬ ì„±ëŠ¥ ì§€í‘œë¥¼ ë™ì‹œì— ê³ ë ¤:

```python
def multi_objective(theta):
    tracking_error = ...
    control_effort = ...
    return w1 * tracking_error + w2 * control_effort
```

### 2. ì˜¨ë¼ì¸ í•™ìŠµ

ì‹œë®¬ë ˆì´ì…˜ ì¤‘ì— ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸:

```python
# ê° ì—í”¼ì†Œë“œë§ˆë‹¤
theta = ioc.learn_cost_weights([latest_demo], theta_init=theta_current)
apply_learned_weights_to_mpc(controller, theta)
```

### 3. ì œì•½ì¡°ê±´ í•™ìŠµ

ë¹„ìš©í•¨ìˆ˜ë¿ë§Œ ì•„ë‹ˆë¼ ì œì•½ì¡°ê±´ë„ í•™ìŠµ:

```python
# Lagrange ìŠ¹ìˆ˜ ë¶„ì„
lambda_active = find_active_constraints(demos)
learned_constraints = construct_constraints(lambda_active)
```

## ì°¸ê³ ë¬¸í—Œ

### ë…¼ë¬¸

1. **Englert et al. (2017)**: "Inverse KKT: Learning Cost Functions of Manipulation Tasks from Demonstrations"
2. **Menner et al. (2019)**: "Constrained Inverse Optimal Control with Application to a Human Manipulation Task"
3. **Aswani et al. (2018)**: "Inverse Optimization with Noisy Data"

### ì´ë¡ 

- **KKT Conditions**: Karush-Kuhn-Tucker ìµœì ì„± ì¡°ê±´
- **Convex Optimization**: Boyd & Vandenberghe
- **Inverse Reinforcement Learning**: Abbeel & Ng (2004)

## ë¼ì´ì„¼ìŠ¤

MIT License

## ë¬¸ì˜

ì´ìŠˆë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ GitHub Issuesì— ë‚¨ê²¨ì£¼ì„¸ìš”.

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** 2026-02-09