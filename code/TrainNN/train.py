# train_residual_nn.py
"""
ë°ì´í„° ë¡œë“œ â†’ ì‹ ê²½ë§ í•™ìŠµ â†’ ëª¨ë¸ ì €ì¥

- ì…ë ¥: delta_tau_dataset.npz (test5.pyì—ì„œ ìƒì„±)

- í•™ìŠµ ê³¼ì •:

ë°ì´í„° 80/20ìœ¼ë¡œ ë¶„í• 
MSE ì†ì‹¤ë¡œ Adam ìµœì í™” (40 epochs)
ê²€ì¦ì…‹ì—ì„œ ì„±ëŠ¥ í‰ê°€
ëª¨ë¸ ì €ì¥

- ì¶œë ¥: residual_nn.pt (í•™ìŠµëœ ëª¨ë¸)

"""

import os
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader


# ==============================
# Model (reuse your structure)
# ==============================
class ResidualTorqueNN(nn.Module):
    def __init__(self, delta_tau_max):
        super().__init__()
        self.delta_tau_max = float(delta_tau_max)

        # self.net = nn.Sequential(
        #     nn.Linear(9, 64),
        #     nn.ReLU(),
        #     nn.Linear(64, 64),
        #     nn.ReLU(),
        #     nn.Linear(64, 3),
        #     nn.Tanh(),  # output in [-1, 1]
        # )
        self.net = nn.Sequential(
            nn.Linear(3, 64),
            nn.ReLU(),
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Tanh(),  # output in [-1, 1]
        )

    def forward(self, x):
        # x: (..., 9)
        return self.delta_tau_max * self.net(x)


def set_seed(seed: int = 0):
    """
    ì‹¤í—˜ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ë„ ê±°ì˜ ë™ì¼í•˜ê²Œ ì¬í˜„ë˜ë„ë¡
    ëª¨ë“  â€˜ë¬´ì‘ìœ„ì„±(randomness)â€™ì˜ ì¶œë°œì ì„ ê³ ì •í•˜ëŠ” ì¥ì¹˜
    """
    np.random.seed(seed) # NumPyì˜ ë‚œìˆ˜ ìƒì„±ê¸°ë¥¼ ê³ ì • 
    torch.manual_seed(seed) # PyTorchì˜ ë‚œìˆ˜ ìƒì„±ê¸°ë¥¼ ê³ ì •


def main():
    set_seed(0)

    # ==============================
    # Config : ì‹¤í—˜ ì¡°ê±´ì„ ì •ì˜ 
    # ==============================
    DATA_PATH = "/home/seohy/colcon_ws/src/olaf/ffw/code/dataGet/delta_tau_dataset.npz"
    DELTA_TAU_MAX = 50.0
    BATCH_SIZE = 128  # í•œ ë²ˆì˜ gradient updateì— ì‚¬ìš©í•  ìƒ˜í”Œ ìˆ˜ (Q)
    EPOCHS = 200       # ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí•´ì„œ í•™ìŠµí• ì§€ 
    LR = 1e-3         # í•™ìŠµë¥  (learning rate)
    WEIGHT_DECAY = 0.0 # ê°€ì¤‘ì¹˜ ê°ì‡  (L2 ì •ê·œí™”)
    GRAD_CLIP_NORM = 1.0  # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (Noneì´ë©´ ì‚¬ìš© ì•ˆ í•¨) (Q)  
    TRAIN_RATIO = 0.8 # í›ˆë ¨ì…‹ ë¹„ìœ¨ (80% í›ˆë ¨, 20% ê²€ì¦)

    # JOINT_NAMES = ["r_sh_p", "r_sh_r", "r_elb"]
    JOINT_NAMES = ["r_sh_p"]

    assert os.path.exists(DATA_PATH), f"Dataset not found: {DATA_PATH}"

    # ==============================
    # Load dataset
    # ==============================
    data = np.load(DATA_PATH)
    q = data["q"]              # (N, 3)
    qdot = data["qdot"]        # (N, 3)
    tau_mpc = data["tau_mpc"]  # (N, 3)
    delta_tau = data["delta_tau"]  # (N, 3)

    # Build x = [q(3), qdot(3), tau_mpc(3)] => (N, 9)
    x = np.concatenate([q, qdot, tau_mpc], axis=1).astype(np.float32)

    # Clip y to [-5, +5] as required
    y = np.clip(delta_tau, -DELTA_TAU_MAX, DELTA_TAU_MAX).astype(np.float32)

    # Validate shapes : í•™ìŠµ ì¤‘ ì´ìƒí•œ shape errorë¥¼ ì´ˆê¸°ì— ì¡ê¸° ìœ„í•´
    N = x.shape[0]
    # assert x.shape == (N, 9), f"x shape mismatch: {x.shape}"
    assert x.shape == (N, 3), f"x shape mismatch: {x.shape}"
    # assert y.shape == (N, 3), f"y shape mismatch: {y.shape}"
    assert y.shape == (N, 1), f"y shape mismatch: {y.shape}"



    # ==============================
    # Train/Val split : ë°ì´í„°ì…‹ì„ í›ˆë ¨ì…‹ê³¼ ê²€ì¦ì…‹ìœ¼ë¡œ ë¶„í•  ğŸ‘‰ ë°ì´í„° ì¸ë±ìŠ¤ë¥¼ ì„ì€ ë’¤, ì•ìª½ì€ í›ˆë ¨ìš© / ë’¤ìª½ì€ ê²€ì¦ìš©ìœ¼ë¡œ ë‚˜ëˆˆë‹¤
    # ==============================
    """
    ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ìˆ˜ì§‘í•œ (ìƒíƒœ, í† í¬) ë°ì´í„°ë¥¼
    ê³µì •í•˜ê²Œ ë‚˜ëˆ„ê³ ,
    í•™ìŠµì´ ì•ˆì •ì ìœ¼ë¡œ ëŒì•„ê°€ë„ë¡ PyTorch í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ëŠ” ë‹¨ê³„
    """
    idx = np.arange(N)
    np.random.shuffle(idx)
    n_train = int(TRAIN_RATIO * N) # ì „ì²´ ì¤‘ í›ˆë ¨ ë°ì´í„° ê°œìˆ˜    
    train_idx, val_idx = idx[:n_train], idx[n_train:]

    x_train, y_train = x[train_idx], y[train_idx] 
    x_val, y_val = x[val_idx], y[val_idx]

    # Torch tensors (NumPy â†’ PyTorch Tensor ë³€í™˜)
    x_train_t = torch.from_numpy(x_train)
    y_train_t = torch.from_numpy(y_train)
    x_val_t = torch.from_numpy(x_val)
    y_val_t = torch.from_numpy(y_val)

    # DataLoader êµ¬ì„± (ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê³µê¸‰)
    train_loader = DataLoader(
        TensorDataset(x_train_t, y_train_t),
        batch_size=BATCH_SIZE,
        shuffle=True, # ë§¤ epochë§ˆë‹¤ ë°ì´í„° ìˆœì„œë¥¼ ë‹¤ì‹œ ì„ìŒ -> ì¼ë°˜í™”ì— ë„ì›€(not í¸í–¥)
        drop_last=False,
    )

    val_loader = DataLoader(
        TensorDataset(x_val_t, y_val_t),
        batch_size=BATCH_SIZE,
        shuffle=False,
        drop_last=False,
    )

    # ==============================
    # Model / Optim / Loss
    # ==============================
    device = torch.device("cpu") # CPUì—ì„œ í•™ìŠµ (GPUê°€ ìˆìœ¼ë©´ "cuda"ë¡œ ë³€ê²½ ê°€ëŠ¥)
    model = ResidualTorqueNN(delta_tau_max=DELTA_TAU_MAX).to(device)
    criterion = nn.MSELoss() # ì†ì‹¤ í•¨ìˆ˜ = í‰ê·  ì œê³± ì˜¤ì°¨ -> íšŒê·€ ë¬¸ì œì— ì í•© : Î”Ï„trueâ€‹âˆ’Î”Ï„pred
    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)

    # ==============================
    # Training loop
    # ==============================

    """
    Epoch ë°˜ë³µ
    â”œâ”€ Train ë‹¨ê³„ (ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ O)
    â”‚    â””â”€ batch ë‹¨ìœ„ë¡œ forward â†’ loss â†’ backward â†’ update
    â””â”€ Validation ë‹¨ê³„ (ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ X)
        â””â”€ ì„±ëŠ¥ í‰ê°€ë§Œ

    """
    train_losses, val_losses = [], []

    for epoch in range(1, EPOCHS + 1):
        model.train() # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì „í™˜
        running = 0.0
        for xb, yb in train_loader:
            xb = xb.to(device) # ë°°ì¹˜ ì…ë ¥ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            yb = yb.to(device) # ë°°ì¹˜ íƒ€ê¹ƒì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™

            pred = model(xb)   # NNì´ Î”Ï„_hat ì˜ˆì¸¡
            loss = criterion(pred, yb) # ì‹¤ì œ Î”Ï„_trueì™€ ë¹„êµ â†’ ì†ì‹¤ ê³„ì‚°(MSE)

            optimizer.zero_grad() # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
            loss.backward() # ì—­ì „íŒŒë¡œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° -> loss ê¸°ì¤€ìœ¼ë¡œ ê° ê°€ì¤‘ì¹˜ì— ëŒ€í•œ loss ë³€í™”ëŸ‰ ì‚°ì¶œ => ì´ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ê¸ˆ ë°”ê¾¸ë©´, ì˜¤ì°¨ê°€ ëŠ˜ì–´ë‚ ê¹Œ ì¤„ì–´ë“¤ê¹Œ ?
            if GRAD_CLIP_NORM is not None:
                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_NORM)
            optimizer.step() # Adamì´ ê³„ì‚°ëœ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•´ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸

            running += loss.item() * xb.size(0) # ë°°ì¹˜ ì†ì‹¤ ëˆ„ì  (ë°°ì¹˜ í¬ê¸° ê³±í•´ì„œ) -> í‰ê· ë‚´ì•¼í•´ì„œ 

        train_loss = running / len(train_loader.dataset) # epoch ì „ì²´ í‰ê·  loss
        train_losses.append(train_loss)                  # ê¸°ë¡

        # Validation
        model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (ë“œë¡­ì•„ì›ƒ/ë°°ì¹˜ì •ê·œí™” ë“± ë¹„í™œì„±í™”) 
        running = 0.0
        with torch.no_grad(): # í‰ê°€ ë‹¨ê³„ì—ì„œëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì•ˆ í•¨ -> ë©”ëª¨ë¦¬ ì ˆì•½
            # ì§€ê¸ˆ ëª¨ë¸ì´ ì²˜ìŒ ë³´ëŠ” ë°ì´í„°ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ë§ì¶”ëŠ”ê°€?
            for xb, yb in val_loader:
                xb = xb.to(device)
                yb = yb.to(device)
                pred = model(xb)
                loss = criterion(pred, yb)
                running += loss.item() * xb.size(0)

        val_loss = running / len(val_loader.dataset) # Validation í‰ê·  loss
        val_losses.append(val_loss)

        if epoch % 5 == 0 or epoch == 1 or epoch == EPOCHS:
            print(f"[Epoch {epoch:03d}/{EPOCHS}] train={train_loss:.6f}  val={val_loss:.6f}")

    # ==============================
    # Plot loss curves
    # ==============================
    plt.figure(figsize=(7, 4))
    plt.plot(train_losses, label="train")
    plt.plot(val_losses, label="val")
    plt.xlabel("Epoch")
    plt.ylabel("MSE Loss")
    plt.title("ResidualTorqueNN Offline Training Loss")
    plt.grid(True)
    plt.legend()
    plt.show()

    # ==============================
    # Error metrics on val set
    # ==============================
    model.eval()
    with torch.no_grad():
        pred_val = model(x_val_t.to(device)).cpu().numpy()

    err = y_val - pred_val  # (N_val, 3)
    mean_abs_err = np.mean(np.abs(err), axis=0) # ê° ê´€ì ˆë³„ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
    max_abs_err = np.max(np.abs(err), axis=0) # ê° ê´€ì ˆë³„ ìµœëŒ€ ì ˆëŒ€ ì˜¤ì°¨

    print("\n[Validation error] joint-wise |Î”Ï„_true - Î”Ï„_hat|")
    for j, name in enumerate(JOINT_NAMES):
        print(f"- {name:6s}: mean={mean_abs_err[j]:.4f} Nm, max={max_abs_err[j]:.4f} Nm")

    # ==============================
    # Save model : ëª¨ë¸ ì €ì¥ !
    # ==============================
    save_path = "/home/seohy/colcon_ws/src/olaf/ffw/code/TrainNN/residual_nn.pt"
    torch.save(
        {
            "model_state_dict": model.state_dict(),
            "delta_tau_max": DELTA_TAU_MAX,
            # "input_dim": 9,
            "input_dim": 3,
            "output_dim": 3,
            "joint_names": JOINT_NAMES,
        },
        save_path,
    )
    print(f"\nSaved trained model: {save_path}")

  
    plt.figure(figsize=(10,3))
    for i, name in enumerate(JOINT_NAMES):
        plt.subplot(1,3,i+1)
        plt.hist(y[:,i], bins=100)
        plt.title(name)
        plt.grid(True)
    plt.show()

if __name__ == "__main__":
    main()
